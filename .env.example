# Context Environment Configuration
# Copy this file to .env and customize for your environment

# Application Settings
APP_NAME=Context
APP_VERSION=0.1.0
ENVIRONMENT=development

# Database Configuration
DATABASE_URL=postgresql://context:password@localhost:5432/context_dev
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_MAX_CONNECTIONS=50

# Qdrant Vector Database
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=context_vectors
# QDRANT_VECTOR_SIZE: 384 for sentence-transformers, 768 for Google embeddings
QDRANT_VECTOR_SIZE=384
QDRANT_API_KEY=
QDRANT_TIMEOUT=30
QDRANT_MAX_RETRIES=3

# Ollama AI Processing
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_DEFAULT_MODEL=codellama:7b
OLLAMA_TIMEOUT=300

# Server Configuration
HOST=0.0.0.0
PORT=8000
RELOAD=true
WORKERS=1

# API Authentication
API_AUTH_ENABLED=false
API_AUTH_SCHEME=api_key
API_KEY=

# Rate Limiting\nRATE_LIMIT_ENABLED=false\nRATE_LIMIT_REQUESTS_PER_MINUTE=60\nRATE_LIMIT_KEY=ip\n

# MCP Server Configuration

# Conversation State (in-memory)
CONVERSATION_STATE_ENABLED=true
CONVERSATION_MAX_CONVERSATIONS=1000
CONVERSATION_MAX_MESSAGES_PER_CONVERSATION=100
CONVERSATION_TTL_SECONDS=3600

MCP_ENABLED=true
MCP_SERVER_NAME=Context
MCP_SERVER_VERSION=0.1.0
MCP_CAPABILITIES=["health_check","capabilities","semantic_search"]
MCP_CONNECTION_TIMEOUT=30
MCP_MAX_RETRIES=3

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Performance Settings
MAX_SEARCH_RESULTS=50
CACHE_TTL_SECONDS=1800
INDEXING_BATCH_SIZE=100

# Embeddings Configuration
# Provider options: 'sentence-transformers' (default), 'google', 'unixcoder'
EMBEDDINGS_PROVIDER=sentence-transformers
UNIXCODER_ENABLED=false

# Google Embeddings (if using EMBEDDINGS_PROVIDER=google)
GOOGLE_API_KEY=
GOOGLE_EMBEDDING_MODEL=text-embedding-004

# File System Monitoring
INDEXED_PATHS=["./"]
IGNORE_PATTERNS=[".git",".venv","__pycache__","node_modules",".pytest_cache"]

# Hardware Requirements
MIN_MEMORY_GB=8
MIN_CPU_CORES=4
MIN_DISK_SPACE_GB=10
